# ğŸ§  Auto-ml tool & common cloud storage interface

A modular, production-ready machine learning workflows library for general purpose modeling on tabular dataset.

This repository combines best practices in machine learning engineering â€” data acquisition from kaggle , data pre-processing, model training and evaluation, tracking with MLflow, and rigorous code quality with pre-commit hooks and unit testing.
The final working package can be installed as .whl binary and can be built with simple commands after cloning this github repo.

---

## ğŸ“š Table of Contents

- [ğŸ”§ Features](#-features)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸš€ Getting Started](#-getting-started)
- [ğŸ‹ï¸â€â™‚ï¸ Training the Model](#ï¸-training-the-model)
- [ğŸ§ª Running Tests](#-running-tests)
- [ğŸŒ Serving via Web App](#-serving-via-web-app)
- [ğŸ“¦ Docker Deployment](#-docker-deployment)
- [ğŸ“Š MLflow Integration](#-mlflow-integration)
- [ğŸ’¡ API Usage Example](#-api-usage-example)
- [ğŸ§° Development Practices](#-development-practices)
- [ğŸ“ Notebooks & Data](#-notebooks--data)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

---

## ğŸ”§ Features

- âœ… End-to-end ML prediction (both regression & classification) workflow
- âœ… Clean, modular Python codebase
- âœ… MLflow for experiment tracking
- âœ… Integration with top 3 cloud storage services
- âœ… Pre-commit hooks (Black, Flake8, isort, etc.)
- âœ… Pytest unit testing
- âœ… Logging and configuration management

---

## ğŸ“ Project Structure

```text
src/
â””â”€â”€ mlutils/
    â”œâ”€â”€ cloud
    â”‚   â”œâ”€â”€ azure.py            # Azure
    â”‚   â”œâ”€â”€ aws.py            # Amazon Web Services
    â”‚   â”œâ”€â”€ gcp.py            # Google Cloud Platform
    â”‚
    â”œâ”€â”€ automl/
    â”‚   â”œâ”€â”€ train.py          # Model training logic
    â”‚   â”œâ”€â”€ eval.py           # Evaluation metrics
    â”‚
    â””â”€â”€ utils/
        â””â”€â”€ utils/
            â”œâ”€â”€ config.py        # Configuration and hyperparameters
            â”œâ”€â”€ io.py            # Data loading and I/O utilities
            â”œâ”€â”€ logger.py        # Logging setup
            â”œâ”€â”€ mlflow_utils.py  # MLflow integration
            â”œâ”€â”€ kaggle.py        # Kaggle Interface
tests/
â””â”€â”€ tests/
    â””â”€â”€ __init__.py               # Unit test definitions
```
---

# ğŸš€ Getting Started

## 0. Pre-requisites
There are several pre-requisites to be able to use this functionality by simply cloning and installing the python package as it is.

* Poetry should be installed in the base python environment. Dev system used conda to build the base working virtual environment and poetry to handle all further dependencies.

* To use mlflow with a cloud backend - an object store and the remote database needs to be created.
    * This project is using AWS RDS (using postgres) as the backend database and AWS S3 as the artifact store.
    * To reproduce the same, AWS credentials need to be pre-configured inside the env either via aws cli or via .env file.
    * A backend store either locally or remotely needs to be created. Same thing applies to a backend db as well.
    * Postgres db connection string needs to be provided
    * For using another backend store natively compatible with mlflow, please pass their db connection string and backend store url
    * In case you want to run the local mlflow server, uncomment the commands following the comment starting with "For local testing..." and comment the current commands.

* To use the respective cloud services their respective credentials need to be passed to the working environment.
    * For local uses, a simple .env file inside the current repo is sufficient. The gitignore config already excludes .env files thus voiding the chances of accidentally committing confidential secrets.
    * For additional security, the ENV variables can be set globally directly from terminal or a bash script outside the repo.
    * For production use cases, it is best to use a managed service such as AWS KMS/Hashicorp Vault or equivalent to pass env variables.
    * For simpler production cases such as an isolated service deployed on ECS one can specify ENV var directly in task specification or link to a file. (This is AWS specific, follow other vendors' docs for their specific steps)
    * ENV VARS that can be specified. None of them are a must unless the specific service is meant to be used.
        * KAGGLE_KEY
        * KAGGLE_USERNAME
        * KAGGLEHUB_CACHE
        * AZ_TENANT_ID
        * AZ_CLIENT_ID
        * AZ_CLIENT_SECRET
        * AZ_STORAGE_ACCOUNT_NAME
        * AZ_CONTAINER_NAME
        * GCP_SERVICE_ACCOUNT_JSON
        * AWS_ACCESS_KEY_ID
        * AWS_SECRET_ACCESS_KEY
        * AWS_DEFAULT_REGION
        * POSTGRES_DB

## 1. Package install
```
git clone https://github.com/mandrake-bio/mlutils
cd mlutils

## For local testing
poetry install

## For distributing production build
poetry build
pip install dist/mlutils-0.1.0-py3-none-any.whl

./mlflow.sh

```

## 2. How to use?
Please follow the jupyter notebook titled Tutorial.ipynb for detailed explanation on how to use the package.

## 3. Running Tests ğŸ§ª
Use pytest to run all unit tests:
```
pytest src/tests/
```

For test coverage:
```
pytest --cov=mlutils tests/
```


# ğŸ§° Development Practices
This repository follows strict development standards:

Git version control

Pre-commit hooks for linting, syntax errors, formatting, and secrets

MLflow for reproducible ML experiments

Logging to track events

Unit tests for all major components.

# ğŸ“ Notebooks & Data
Jupyter notebooks for data exploration and EDA are in the /notebooks directory.

Training and test datasets should be placed in relevant subdirectories inside /data.

# Future Directions
* Handle file formats outside of csv
* Handle dataset comprised of multiple files
* Support for multi-label classification
    * Updating param_grid models to pass multi-label hyper-params
* Allow for custom pre-processing and feature engineering
* Support for neural networks
    * Add support for both pytorch and tensorflow
    * Integrate tf/pytorch nns directly with sklearn pipeline for tabular datasets
    * Create new interface - for unstructured data: images, audio, natural language.
* Cloud
    * Unifying cloud interface with a single class
    * Adding support for functionality beyond just storage:
        * Interacting with LLMs
        * Interacting with databases
        * Analytics on cloud compute usage
* MLFlow enhancements
    * Incorporating SHAP plots into mlflow artifacts
    * Automatically register model based on experiment metrics
    * Automatically serve model
* Enhancing unit test coverage

# ğŸ¤ Contributing

Contributions are welcome!

Fork the repo

Create your feature branch (git checkout -b feature/AmazingFeature)

Commit your changes (git commit -m 'Add amazing feature')

Push to the branch (git push origin feature/AmazingFeature)

Open a Pull Request

Ensure you follow the code standards and include relevant unit tests.

# ğŸ“„ License
Distributed under the MIT License. See LICENSE for more information.

# ğŸ™Œ Acknowledgments
This project integrates tools and practices from:

Scikit-learn

Flask

MLflow

Docker

Pandas / NumPy

Pytest

Pre-commit

GitHub Actions (optional CI/CD integration)

**This file is completely self-contained and fully detailed. You can copy this directly into your project as `README.md` without needing any additional documents. Let me know if you'd like me to generate a badge section or add sample config templates in-code!**
